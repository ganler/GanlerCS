# ML下的概率和信息论 - 2



## 常用概率分布

### Bernoulli(伯努利)分布

又称“零一分布”或“两点分布”。高中学过。
$$
P(x=1) = \phi\\
P(x=0)=1-\phi\\
\mathbb{E}[x]=\phi\\
Var(x)=\mathbb{E}[(x-\mathbb{E}[x])^2]=\phi-\phi^2=\phi(1-\phi)
$$

### Multinoulli分布

即多项式分布。伯努利分布只有0和1，而多项式分布有多个结果（我们假设有k个）。
$$
P(x=x_k)=p_k\\
\sum_{i=1}^k p_k=1\\
\mathbb{E}[x]=\sum_{i=1}^k x_k\times p_k\\
Var(x) =\mathbb{E}[x^2]-\mathbb{E}[x]^2
$$

### 高斯分布

也称正态分布（normal distributuin)，是最常用的分布。
$$
N(x;\mu,\sigma^2)=\sqrt{\frac{1}{2\pi\sigma^2}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}\\
\sigma 是方差\\
\mu 是期望
$$
![](https://ws2.sinaimg.cn/large/006tKfTcly1ftkvt2yk15j30po0cg0u6.jpg)

$\mu=0（对称轴横坐标）,\sigma=1$称为标准正态分布。

令$\beta=\frac{1}{\sigma^2}$，即为精度。（方差的倒数）

​	当我们由于缺乏关于某个实数上分布的先验知识而不知道该选择怎样的形式时，正态分布是默认的比较好的选 择，其中有两个原因：

* 我们想要建模的很多分布的真实情况是比较接近正态分布的。 **中心极限定理(central limit theorem)**说明很多独立随机变量的和近似服从正态分布。这意味着在实际中，很多复杂系统都可以被成功地建模成正态分布的噪声，即使系统可以被分解成一些更结构化的部分。 
* 在具有相同方差的所有可能的概率分布中，正态分布在实数上具有<u>最大的不确定性</u>。 

将之拓展到n维空间，多维正态分布：
$$
N(x;\mu,Σ)= \sqrt{\frac{1}{(2\pi)^ndet(Σ)}}e^{(-\frac{1}{2}(x-\mu)^TΣ^{-1}(x-\mu))}\\
n=1:N(x;\mu,\sigma^2)=\sqrt{\frac{1}{2\pi\sigma^2}}e^{-\frac{1}{2\sigma^2}(x-\mu)^2}
$$
$Σ$是协方差矩阵（正定的对称矩阵）；$\mu,x$是向量。

此时对$Σ$求逆：令$\beta=Σ^{-1}$，为精度矩阵。

关于$3\sigma$原则参见：[wiki百科](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule)

### 指数分布和$Laplace$分布

**指数分布**

在深度学习中，我们经常需要一个在$x=0$取得边界值(sharp point)的分布（比如让x取负值的概率为0）。为实现此：
$$
p(x;\lambda)=\lambda {\bold 1}_{x\ge 0}e^{(-\lambda x)}
$$
$\bold 1_{x\ge 0}$在x小于0时为0。

**拉普莱斯分布**

在任意一点$\mu$处设置概率质量的峰值：
$$
Laplace(x;\mu,\gamma)=\frac{1}{2\gamma}e^{(-\frac{|x-\mu|}{\gamma})}
$$

### Dirac分布和经验分布

> 略



### 分布的混合

<u>通过组合一些简单的分部来定义新的概率分布</u>。

**混合分布**有一些 <u>组件分布</u> 构成。样本是由哪个组件分布产生取决于从一个多项式分布中采样的结果：
$$
P(x)=\sum_iP(c=i)P(x|c=i)
$$
$P(x)$是对各组件的多项式分布。也就是说先把被混合的概率分布模型用多项式分布处理（分配好各分布的权重），再去乘上对于分布下的概率值。这其中有个很重要的概念：**潜变量**（latent variable）。潜变量就是我们不能直接观测到的随机数变量。比如上述的c，其对应不同的模型。潜变量在联合分布中可能和 x 有关，在这种情况下，$P (x, c) = P (x | c)P (c)$。

​	一个非常强大且常见的混合模型是 **高斯混合模型(Gaussian Mixture Model)**， 它的组件$ p(x | c = i)$ 是不同参数的高斯分布。

​	除了均值和协方差以外，高斯混合模型的参数指明了给每个组件 i 的 **先验概率 (prior probability)** $α_i = P(c = i)$。‘‘先验’’ 一词表明了在观测到 x 之前传递给模型关于 c 的信念。作为对比，$P (c | x)$ 是 **后验概率(posterior probability)**，因为它 是在观测到 x 之后进行计算的。

> 直观点的描述可以认为，不同范围内的x对应<u>不同的类型</u>（$\mu和\sigma$不同）的高斯分布，选择不同类型的高斯分布时，我们用*先验概率*，选择后再在对应的高斯分布模型下，我们用*后验概率*。

高斯混合模型是概率密度的 **万能近似器(universal approximator)**(连续泰勒级数和傅里叶级数这些概念，都是通过合并来拟合)，在这种意义下，任何平滑的概率密度都可以用具有足够多组件的高斯混合模型以任意精度来逼近。



## 最大似然估计

在我的另一篇关于[Logistic回归](https://ganler.github.io/2018/07/25/ML-in-python3-Logistic%E5%9B%9E%E5%BD%92/)的文章的末尾，已有最大似然估计的相关知识。

这里更加详细的说明一下最大似然估计：

> 最大似然估计是利用<u>已知的样本的结果</u>（$x=[x_1,x_2,\cdots,x_n]$），在使用<u>某个模型</u>$f(x)$的基础上，反推<u>最有可能导致这样结果的模型参数值</u>$w$。

> ​        $f(x=[x_1,x_2,\cdots,x_n]|w)$表示 <u>w确定后</u> 的 <u>模型f</u> 下 <u>已知样本结果同时发生</u> 的**概率**。
>
> ​	通过贝叶斯规则我们知道什么是似然，即表示在<u>承认先验的条件下</u>另外一个与之相关的随机变量的表现。我们定义似然L：
> $$
> L(w|x)=f(x|w)
> $$
>
> **最大似然估计即让我们定义的似然达到最大值。然后我们要做的就是提取其对应的参数（w）**
>
> 而计算$f(x|w)$的计算量是很可怕的，故我们假设变量相互独立，则原式可被改写为：
> $$
> L(w|x)=f(x|w)=\prod_{i=1}^nf(x_i|w)
> $$
> 我们只是求最大值，所以可以对原有函数进行一些变换。而我们知道对连乘式求导有点困难，所以我们想着要取对数，将连乘变成加法，方便求导。
> $$
> \ln L(w|x)=\ln \prod_{i=1}^nf(x_i|w)=\sum_{i=1}^n\ln f(x_i|w)\\
> 左边称之为对数似然
> $$
> 我们要的东西就是$\arg_w \max \sum_{i=1}^n\ln f(x_i|w)$
>
> 上面的w其实就只是参数而已，不同模型有不同的参数。而x是自变量。我们先尝试把模型整理为$f(x)_{args}$。arg代表参数。然后将模型直接带入似然中，再带入已知的x，求最大值时对应的参数值即可。

> **以伯努利分布为例子**
> $$
> \begin{aligned}
> & P(x=1)=p,P(x=0)=1-p\\
> & P(x)=p^x(1-p)^{(1-x)}\\
> & 有样本x_1,x_2,...,x_n\  in\  \{0, 1\}\\
> & 求\arg_p \max \sum_{i=1}^n\ln p^{x_i}(1-p)^{(1-x_i)}:\\
> & 原式=\arg_p \max \sum_{i=1}^n[x_i\ln p+(1-x_i)\ln(1-p)]\\
> & \frac{d(\sum_{i=1}^n[x_i\ln p+(1-x_i)\ln(1-p)])}{dp}=\sum_{i=1}^n[\frac{x_i} {p}-\frac{1-x_i}{1-p}]\\
> & 令之为0\\
> & 得(1-p)\sum x_i=p\sum(1-x_i)\rightarrow p=\frac{\sum^n_{i=1} x_i}{n}
> \end{aligned}
> $$
> 同样，如果是高斯分布：
> $$
> p(x)=\frac{1}{\sqrt{2\pi}\sigma}e^{(-\frac{(x-\mu)^2}{2\sigma^2})}
> $$
>
> 你会得到：
> $$
> \mu=\frac{\sum_{i=1}^n x_i}{n}\\
> \sigma^2=\frac{\sum_{i=1}^n(x_i-\mu)^2}{n}
> $$
>



## 常用函数性质

### Sigmoid

我们在输出连续性上讨论过 *跃阶函数* 和 *sigmoid*函数，跃阶函数在跳跃瞬间的过程不好处理，并且不符合实际，而sigmoid函数有连续的性质，在数学上也易于处理。

> 在梯度下降的时候，我们需要求梯度，这就要求函数可微，而一般的跃阶函数在跳跃过程是无法求导的，所以才有了用其他可微函数进行代替的思想。

![img](http://www.ruanyifeng.com/blogimg/asset/2017/bg2017071208.png)

![img](http://www.ruanyifeng.com/blogimg/asset/2017/bg2017071209.png)

其中 *Sigmoid函数*：
$$
\sigma(z) = \frac{1}{1+e^{-z}}\\
在神经网络中，我们一般记:z=w^Tx+b(w是权重分配向量，b是阈值的负数)
$$
​	因此，为了实现Logistic回归分类器，我们可以在每个特征对应的数值上都乘以一个<u>回归系数</u>（翻译为 *weight* ，也称权重），然后把所有的结果值相加，将这个总和代入Sigmoid函数中，进而得到一个范围在0~1之间的数值。任何大于0.5的数据被分入1类，小于0.5即被归入0类。所以，Logistic回归也可以被看成是一种概率估计。

![](https://ws2.sinaimg.cn/large/006tKfTcly1ftjp1uacioj30pi0m6n0j.jpg)

> **Sigmoid**详解：
> $$
> \sigma(z) = \frac{1}{1+e^{-z}}
> $$
> ​	若w给定：$z = w^Tx,令h_w(x)=\sigma(z)$。$Sigmoid$函数可以将定义域内的自变量映射到[0, 1]空间。若$h_w(x_0)=p\% \in[0, 1]$，则可以解释为$x=x_0$时，得到的结果有$p\%$的可能为1，$1-p\%$为0。
>
> ​	假设我们要利用该方法过滤垃圾邮件，我们定义正常邮件为正类（结果为1），垃圾邮件为负类（结果为0）。通过计算出的概率值可以判定邮件是否为垃圾邮件。
>

### Softplus

$$
softplus(x)=\ln(1+e^x)
$$

如果说sigmoid是为了使
$$
f(x)=
\left\{ 
\begin{aligned}
1,x\ge0\\
0,x<0
\end{aligned}
\right.
$$
变得平滑。那么softplus函数就是为了使ReLu函数:$max(x,0)$变得平滑：

![pic1](http://image.bubuko.com/info/201707/20180111000007588505.png)

### 重要结论

$$
\begin{aligned}
&\sigma(x)'=\sigma(x)(1-\sigma(x))\\
&\sigma(x)+\sigma(-x)=1\\
&\sigma(x)=\frac{1}{1+\exp(-x)}\\
&\sigma^{-1}(x)=\ln(\frac{x}{1-x})(又被称作分对数)\\
&\\
&\ln\sigma(x)=-ζ(-x)\\
&\\
&ζ(x)'=\sigma(x)\\
&ζ(x)=\int\sigma(x)dx\\
&ζ(x)-ζ(-x)=x\\
&ζ^{-1}(x)=\ln(\exp(x)-1)

\end{aligned}
$$



### 信息论基础

这是一个很好玩的话题。

我们先讲一个东西——**香农熵**（信息熵）。

同样，在[这篇博客](https://ganler.github.io/2018/07/25/ML-in-python3-%E5%86%B3%E7%AD%96%E6%A0%91/)里我简单说了一下香农熵这东西。

#### 香农熵

给你一枚硬币，正面为1，反面为0。

| 丢的次数 | 结果                                   | 结果数 |
| -------- | -------------------------------------- | ------ |
| 1        | 0，1                                   | 2      |
| 2        | 00，11，01，10                         | 2^2=4  |
| 3        | 000，111，001，010，100，011，101，110 | 2^3=8  |

​	结果数就是我们说信息量，丢硬币的次数越多，结果的可能就越多，结果就越不确定，所以我们说其“熵”越大。

​	我们用$h()$表示信息量，比如$h(丢一次硬币)=2$。

​	我们假设今天同时发生了两件事情，火星撞地球了（$x_1$），我今天吃饭了（$x_2$）。

​	那么今天的<u>预期信息量</u>为：
$$
\mathbb{E}(x)=p(x_1)h(x_1)+p(x_2)h(x_2)
$$
​	除此之外，假设说火星撞地球了，因为其十分罕见，我们会想很多问题：为什么撞地球，地球上还有生物吗，是不是只有太空中宇航员活下来了等等。而如果我今天说我吃饭了，我觉得别人除了认为我是zz，别的想都不会想。所以我们得到一个结论：**越罕见的事情，信息量越大，而越容易发生的事情，信息量越小。**取极端的情况，当一件事情发生概率为1时，其信息量为0；当一件事情的发生概率为0的时候，其信息量为无穷大。

​	如果上述两件事情都发生了，易知$h(x)=h(x_1)+h(x_2)$。

​	综上结合已有概率论知识:

> * $\mathbb{E}(x)$随$x_i$单调递增；
> * $p(x_1,x_2)=p(x_1)p(x_2)$
> * $h(x_1,x_2)=h(x_1)+h(x_2)$
> * $h(x_i)$和$p(x_i)$成反比。
> * $p(x)=0,h(x)=+\inf$
> * $p(x)=1,h(x)=0$
> * $p(x),h(x)\ge0$

所以我们很容易想到对数模型，这里定义**奈特**：
$$
h(x_i)=-\ln p(x_i)\\
$$

> 更多的情况会以2为对数的底。

而香农熵就是其期望：
$$
entropy(x)=\mathbb E(x)=-\sum p(x_i)\ln p(x_i)
$$
当香农熵是连续的时候，香农熵被称为**微分熵**：

$$
entropy(x)=-\int_x p(x)\ln p(x)dx=-p(x)\ln p(x)-(1-p)\ln (1-p(x)) 
$$

> p=0.5的时候，熵最大。



#### KL散度(相对熵)

如果我们对于同一个随机变量 x 有两个单独的概率分布$P(x)$和$Q(x)$时：

我们用 **KL散度** 来衡量这两个分布的差异：
$$
D_{KL}(P||Q)=\mathbb E_{\rm x\sim P}[\ln\frac{P(x)}{Q(x)}]=\sum P(x_i)\ln\frac{P(x_i)}{Q(x_i)}
$$
上面是离散的情况，而连续的情况为：
$$
D_{KL}(P||Q)=\int P(x)\ln \frac{P(x)}{Q(x)}dx
$$
当两种分布越是接近，KL散度就越小，反之KL散度越大。

**KL散度大于0**，证明如下：
$$
\begin{aligned}
D_{KL}(P||Q)&=\sum P(x_i)\ln \frac{P(x_i)}{Q(x_i)}\\
&=-\sum P(x_i)\ln \frac{Q(x_i)}{P(x_i)}\\
&\ge -\ln[\sum P(x_i)\cdot \frac{Q(x_i)}{P(x_i)}]\\
&=-\ln 1\\
& =0
\end{aligned}
$$

> 其中第二步到第三步是因为$y=\ln(x)$函数是一个上凸函数。之所以可以这么做是由凸函数的性质导致。

​	KL散度经常被用作分布之间的某种距离。然而，它并不是真的距离因为距离是对称的，而它不是对称的（ 很多时候$D_{KL}(P||Q)\neq D_{KL}(Q||P)$ ）。

> 对于高斯分布而言：
> $$
> D_{KL}(P_1||P_2)=\sum P_1\ln \frac{P_1}{P_2}=\cdots\\
> =\ln \frac{\sigma_2}{\sigma_1}+\frac{\sigma_1^2+(\mu_1-\mu_2)^2}{2\sigma_2^2}-\frac{1}{2}
> $$
> 这里只给出了结论，中间推导就不啰嗦了。

那么如何使用呢？举个🌰：

假设$P_2$是$(\mu_2 = 0,\sigma_2^2=1 )$，现在我们来将解决一个问题，怎样的$P_1$会让$D_{KL}(P_1||P_2)$尽量小(即两种分布尽量近)。

>带入：
>$$
>D_{KL}(P_1||P_2)=-\ln\sigma_1+\frac{\sigma_1^2+\mu_1^2}{2}-\frac{1}{2}
>$$
>因为我们都说$P_1,P_2$是正态分布了，那么肯定是两个模型相同的时候最近，即$\mu_1=\mu_2,\sigma_1=\sigma_2$的时候。
>
>这里我们通过观察可以得到一个结论：
>
>> * $\mu$之间偏移得越大，**KL散度**越大。
>> * $\sigma_1$的影响不是特别明显，因为$-\ln\sigma_1$和$\frac{\sigma_1^2}{2}$增长方向相反。

> 下图引自《深度学习》。

![](https://ws4.sinaimg.cn/large/006tNbRwly1fu8g1tr85hj30xe0te49e.jpg)



