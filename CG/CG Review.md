# CG Review

[TOC]

## **Computer Graphics**

### ğŸ’– What's CG

The study of creating, manipulating, and using virtual images in the computer.

### ğŸ’– CG App

- Game
- Film effect
- CAD
- Visualization

### ğŸ’– Graphic Pipline

- **Application** stage
- **Geometry** stage
- **Rasterization** stage

<img src="https://i.loli.net/2019/12/09/NCSLMraQ6gyKIj2.png" style="zoom:50%;" />



### ğŸ’– The elements of image formation

- Object
- Viewer
- Light Source(s)
- Attributes

### ğŸ’– Pinhole Camera Model

${NAME} describes **the ideal perspective projection of a camera**, without considering the physics of the **lens**(é•œå¤´), the **apeture**ï¼ˆå…‰åœˆï¼‰ and the **film**ï¼ˆèƒ¶ç‰‡ï¼‰.

<img src="https://openmvg.readthedocs.io/en/latest/_images/pinholeCamera.png" style="zoom: 67%;" />

### ğŸ’– Framebuffer

A **framebuffer** is a portion of RAM containing a bitmap that drives a video display. 

### Vertex, primitives & fragment

A **vertex** is a point/node in the space, represented by its <u>coordinate</u> and <u>properties</u>, e.g. color, normal, texture coordinate etc. 

A **primitive** is the basic element of **geometric shapes** and rendering, it is composed of vertices. It can be points, lines, polygons or polyhedrons. 

A **fragment** is the output data of the geometry shader in <u>rasterization stage</u>. The fragment contains the data necessary to generate <u>a single pixel in the frame buffer</u>, e.g. color, depth, normal, texture coordinate etc.

**Geometry**: <u>locations</u> of the vertices.

**Topology**: <u>organization</u> of the vertices and edges.

### Solid Object Representation

- **Surface-based** representation
- **Volume-based** representation
- CSG(constructive solid geometry)
- **Point-based** representation.

## **Transformation**

### ğŸ’– Coordinate Spaces

- Model/Local
- World
- Camera 
- Clip
- NDC

â†‘ 3D/4D

â†“ 2D

- Viewport
- Window

### ğŸ’– Transformation Types

- Translation(<u>*non-linear*</u>) $T(u)=u+v$
- Reflection
- Scaling 
- Shear
- Rotation 

> $$
> T(\alpha u)=\alpha T(u)
> $$
>
> Translation does not follow this rule.
>
> é€†æ—¶é’ˆæ—‹è½¬$\theta$ åº¦ã€‚
> $$
> \left\{\begin{matrix}
> \cos \theta & -\sin \theta\\
> \sin \theta & \cos \theta
> \end{matrix}\right\}
> $$
> How to remember:
> $$
> x\sim\cos(a+b)=\cos a\ \mathbf{cos b} - \sin a\ \mathbf{sin b}\\
> y\sim\sin(a+b)=\cos a\ \mathbf{sin b} + \sin a\ \mathbf{cos b}
> $$
> Shear:
> $$
> \left\{\begin{matrix}
> 1 & a\\
> 0 & 1
> \end{matrix}\right\}
> $$

### ğŸ’– Affine Transformation

> <u>Translation together with linear transformations.</u>

Translation is not linear transformation. And affine transformation helps translation together with linear transformations.

### ğŸ’– Homogeneous Coordinates

`dimension += 1`

é½æ¬¡åæ ‡è¡¨ç¤ºæ˜¯è®¡ç®—æœºå›¾å½¢å­¦çš„é‡è¦æ‰‹æ®µä¹‹ä¸€ï¼Œå®ƒæ—¢èƒ½å¤Ÿç”¨æ¥æ˜ç¡®åŒºåˆ†å‘é‡å’Œç‚¹ï¼ŒåŒæ—¶ä¹Ÿæ›´æ˜“ç”¨äºè¿›è¡Œä»¿å°„ï¼ˆçº¿æ€§ï¼‰å‡ ä½•å˜æ¢ã€‚

## **Viewing**

### ğŸ’– Viewing Transformation

- **Modeling** Transformation(local space -> world space)
- **Camera** Transformation(world space -> camera space)
- **Projection** Transformation(camera -> NDC)
- **Viewport** Transformation(NDC -> window coordinates)

### ğŸ’– Viewing impl

1. Local space -> world space -> camera space.
2. Projection -> view volume. (3D -> 2D)
3. Clip geometry outside the view volume.
4. Project into screen coordinates.

5. Remove hidden surfaces.

### ğŸ’– Orthographic  projection

Just define a orthographic view volume. (A box $\to [-1, 1]^3$)

**Normalized form**

- Move center to the origin;
- Scale to have sides of length 2;
- Remove camera(z) axis.

**Pros:**

- Shapes preserved;
- Good for measurements;

**Cons:**

- Cannot see what object really looks like as many surfaces hidden from view.
- (æˆ‘åŠ çš„) Not realistic from the perspective of humans.

### ğŸ’– Perspective projection

$$
[x_p,y_p,z_p]=[\frac{x_pd}{x}, \frac{y_pd}{y}, d]
$$

**Pros:**

- Realistic;

**Cons:**

- Non-uniform foreshortening;
- More difficult to construct by hand than parallel projections;

> Can be a orthographic projection if $d\to \infin$

**Normalized Form**:

<img src="https://i.loli.net/2019/12/21/7AWkRBmIelynSUt.png" style="zoom:50%;" />

> $$
> P_n=\frac{P_c}{w_c}
> $$

### Diff between NDC & clip space

- **Clip space:** After projection transformation and before perspective division.(w is not 1). 
- **NDC:** The space after perspective division. The homogenous coordinate w of vertex is 1;

### Why does clip performed in the clip space? 

- **Efficiency**;
- **Correctness**: The orginal depth info in kept in clip space, but is normalized in NDC;

### Line clipping: Cohen-Sutherland Algorithm 

- Outcode;

### Polygon clipping: Weiler-Atherton Clipping 

- Walk(é€†æ—¶é’ˆï¼Œé‡åˆ°è¾¹ç•Œä¸”æ˜¯å…¥å°„ï¼Œé‚£ä¹ˆå°±OKï¼Œè¿ç»­çš„å‡ºå°„ç‚¹+å…¥å°„ç‚¹=>è¾¹ç•Œç›´è¿)
- å¦‚æœpolygonçš„ä¸€ä¸ªè§’ç‚¹åœ¨screençš„è¾¹ä¸Šå°±éº»çƒ¦äº†ï¼›

> å…¶ä»–æ–¹æ³•å°±æ‹†ä¸‰è§’å½¢å°±å®Œäº‹äº†ã€‚

## **Visible Surface Detection**

### ğŸ’– Z-Buffer

ç®€å•æ¥è¯´å°±æ˜¯åœ¨viewportä¸Šçš„æ¯ä¸ªåƒç´ ï¼š => Draw if closer.

- è®°å½•å½“å‰ã€Œæœ€è¿‘æ·±åº¦ã€ï¼›
- ä»¥åçš„åƒç´ ï¼Œå¦‚æœè¿œäºæœ€è¿‘æ·±åº¦ï¼Œå°±ä¸ç”»ï¼›
- è¿‘äºæœ€è¿‘æ·±åº¦å°±ç”»&æ›´æ–°å½“å‰ä½ç½®åƒç´ çš„ã€Œæœ€è¿‘æ·±åº¦ã€ã€‚

#### Pros & Cons

- Advantage
  - Simple to implement in hardware. 
  - Memory for z-buffer is now not expensive
  - Diversity of primitives â€“ not just polygons.
  - Unlimited scene complexity
  - Donâ€™t need to calculate object-object intersections.
-  Disadvantage
  - Extra memory and bandwidth
  - Waste time drawing hidden objects
  - Z-precision errors
  - May have to use point sampling 

## **Rasterization**

### ğŸ’– Line Ras

#### DDA

Select pixel vertically closest to line segment.

```c++
dx = x2 - x1, dy = y2 - y1;
step = min(abs(dx), abs(dy)); // èµ°å°çš„
for(int i=0; i<step; ++i)
{
  	x += dx / (step);
  	y += dy / (step);
  	setp(round(x), round(y));
}
```

#### Bresenham

è½¬æ•´æ•°è¿ç®—ï¼›

```c++
void bresenham(int x0, int y0, int x1, int y1) 
{
    int dx = abs(x1 - x0), sx = x0 < x1 ? 1 : -1;
    int dy = abs(y1 - y0), sy = y0 < y1 ? 1 : -1;
    int err = (dx > dy ? dx : -dy) / 2;

    while (setpixel(x0, y0), x0 != x1 || y0 != y1) 
    {
        int e2 = err;
        if (e2 > -dx) { err -= dy; x0 += sx; }
        if (e2 <  dy) { err += dx; y0 += sy; }
    }
}
```

### ğŸ’– Scan Conversion = Fill Polygons 

- Split triagnles
- Fill the spans 

### ğŸ’– Inside test

Odd-Even rule.

<img src="https://i.loli.net/2019/12/22/Na5HROkSiWf7DJK.png" style="zoom:35%;" />

### ğŸ’– Flood Fill

```c++
flood_fill(int x, int y) 
{
    if(read_pixel(x,y) == WHITE) 
    {
				write_pixel(x,y,BLACK); 
      	flood_fill(x-1, y); 
      	flood_fill(x+1, y); 
      	flood_fill(x, y+1); 
      	flood_fill(x, y-1);
		}
}
```

### ğŸ’– Triangulation -> Ear-clipping

é€‰ä¸€ä¸ªç‚¹vï¼Œå’Œä»–é‚»å±…ç»„æˆä¸‰è§’å½¢ç„¶åå¦‚æœè¿™ä¸ªä¸‰è§’å½¢æ˜¯insideï¼Œé‚£ä¹ˆæŠŠè¿™ä¸ªä¸‰è§’å½¢è®°å½•ï¼Œç„¶ååˆ å»vï¼Œå¾€å¤å¾ªç¯ã€‚

## **Illumination**

### ğŸ’– Shading

- Variation in observed color across an obj.
- Cause by how a material reflects light.
  - geometry
  - lighting
  - material

### ğŸ’– Color models

- RGB
- CMY(Cyan, Magenta, Yellow)
- HSV(Hue, Saturation, value)

### ğŸ’– Phong Reflection Model

<img src="https://i.loli.net/2019/12/22/mIj6AsgrYuE2iKJ.png" style="zoom:50%;" />



#### Ambient Reflection

$$
I_a = k_a*L_a
$$

ç¯å¢ƒé¢œè‰² * å¼ºåº¦ç³»æ•°ï¼›

#### Diffuse

$$
I_d=k_d*(\cos<l, n>)*L_d
$$

#### Specular

$$
I_s=\max (k_s L_s \cos <v, r>, 0)
$$

Then add them all.

### ğŸ’– Blinn-Phong reflection model

Replace **cos<v,r>** using **cos<h, n>**, where **h = (v+l)/2**

<img src="https://i.loli.net/2019/11/19/MYSZIlNsLr98qwJ.png" style="zoom:50%;" />

Before any computation, we know $v, n, l$. Computation of $h$ is easy: $h = \frac{l+v}{||l+v||}$ and computation of $r$ is a little bit complex: $r=2*n*(l*n)-l$ .

- The purpose of the modification is to speed up the computation.
- Blinn-Phong reflection model only modified the **specular reflection** stage $\to L_sK_s\max(\frac{l+v}{||l+v||}*n, 0)$

### ğŸ’– Flat shading

Assign all pixels inside each polygon the same color, therefore reveal polygons and fast.

### ğŸ’– Gourand shading

Gourand Shading uses **vertex shader** and **interpolation methods** on fragment color. <u>The color of vertexes are given and the color of fragments are computed by interpolation.</u>

There're mainly 3 steps:

1. Normal averaging;ï¼ˆå¯¹äºæ¯ä¸ªvertexçš„æ³•å‘é‡ç”¨å‘¨å›´è¾¹çš„å¹³å‡å€¼æ¥ä¼°è®¡ï¼‰
2. Vertex lighting;ï¼ˆcompute the color for each vertex based on a shading modelï¼‰
3. Interpolation;ï¼ˆæ—¢ç„¶ç®—å‡ºäº†ç‚¹çš„é¢œè‰²ï¼Œé‚£ä¹ˆå›¾å…ƒå†…éƒ¨åƒç´ å°±é€šè¿‡åŒçº¿æ€§æ’å€¼æ¥ç®—ï¼‰

### ğŸ’– Phong Shading

- Normal interpolation
- Fragment lighting

---



### ğŸ’– Edge Collapse 

### ğŸ’– Vertex removal 

è´å¡å°”æ’å€¼å°±2ä¸ªå°„çº¿ï¼ŒHermitæ’å€¼polyæ’å€¼ï¼›

<img src="https://i.loli.net/2019/12/23/LNmyKJw8eAnFtxM.png" style="zoom:33%;" />

å°±ä¸€ç»„åˆå…¬å¼ï¼›

## OpenGL vs RT

OpenGL is based on a pipeline model in which primitives are rendered one at time 

- No shadows (shadow maps etc.)
- No multiple reflections (environment maps etc.) 

Global approaches 

- Rendering equation 
- Ray tracing 
- Radiosity 
- Easily making effects: shadows, reflections, transparency 

